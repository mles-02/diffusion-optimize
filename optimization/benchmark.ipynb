{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbqNK5HZFB91"
      },
      "source": [
        "## Hardware"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RcfD7BcFDSr"
      },
      "outputs": [],
      "source": [
        "!lscpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pMrBJhtGA-v"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "at7QFFOVE-Ze"
      },
      "source": [
        "## 0. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EEU9T2LJpdce"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade diffusers[torch]\n",
        "!pip install tomesd\n",
        "!pip install \"optimum[onnxruntime, openvino]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNx1VJ5Tp8MM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import time\n",
        "import contextlib\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "class Profile(contextlib.ContextDecorator):\n",
        "    # YOLOv5 Profile class. Usage: @Profile() decorator or 'with Profile():' context manager\n",
        "    def __init__(self, t=0.0):\n",
        "        self.t = t\n",
        "        self.cuda = torch.cuda.is_available()\n",
        "\n",
        "    def __enter__(self):\n",
        "        self.start = self.time()\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, type, value, traceback):\n",
        "        self.dt = self.time() - self.start  # delta-time\n",
        "        self.t += self.dt  # accumulate dt\n",
        "\n",
        "    def time(self):\n",
        "        if self.cuda:\n",
        "            torch.cuda.synchronize()\n",
        "        return time.time()\n",
        "\n",
        "def measure_latency(pipeline, prompt, nsteps=20, nimg=1):\n",
        "    latencies = []\n",
        "    dt = Profile()\n",
        "    # warm up\n",
        "    for _ in range(nimg):\n",
        "        _ =  pipeline(prompt, num_inference_steps=nsteps)\n",
        "    # Timed run\n",
        "    for _ in tqdm(range(nimg)):\n",
        "        with dt:\n",
        "            _ = pipeline(prompt, num_inference_steps=nsteps)\n",
        "\n",
        "    return dt.t / nimg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d70Qy_z_rYB2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n",
        "# from datasets import load_dataset\n",
        "\n",
        "# CONFIG = {\n",
        "#     \"model_id\": \"runwayml/stable-diffusion-v1-5\",\n",
        "#     \"dtype\": torch.float16,\n",
        "#     \"gen\": torch.manual_seed(0),\n",
        "#     \"inference_steps\": 25,\n",
        "#     \"num_images_per_prompt\": 4,\n",
        "#     \"resolution\": 512,\n",
        "#     \"num_parti_prompts\": 100,\n",
        "#     \"challenge\": \"basic\",\n",
        "#     \"seed\": 0,\n",
        "#     \"tome_ratio\": 0.5,\n",
        "# }\n",
        "\n",
        "# prompts = load_dataset(\"nateraw/parti-prompts\", split=\"train\")\n",
        "# prompts = prompts.shuffle()\n",
        "# prompts = [prompts[i][\"Prompt\"] for i in range(10)]\n",
        "prompt = 'Fire and Ice Dragon'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IehwVZB31725"
      },
      "source": [
        "## 1. CPU Benchmark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zajakS961_EO"
      },
      "outputs": [],
      "source": [
        "CPU_DEVICE = 'cpu'\n",
        "NUM_STEPS = 20\n",
        "NUM_IMAGES = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9auZ4OryrJzZ"
      },
      "source": [
        "### Finetuning Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pczwgjAtqfas"
      },
      "outputs": [],
      "source": [
        "model_id = \"Zero-nnkn/stable-diffusion-2-pokemon\"\n",
        "pipeline = StableDiffusionPipeline.from_pretrained(model_id)\n",
        "pipeline.to(CPU_DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8WQqj7d9JEe"
      },
      "outputs": [],
      "source": [
        "t = measure_latency(pipeline, prompt, nsteps=NUM_STEPS , nimg=NUM_IMAGES)\n",
        "print(f'\\n{t} (s/image)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwQqOt2Wt_0t"
      },
      "outputs": [],
      "source": [
        "del pipeline\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-wiQ_jit9JZ"
      },
      "source": [
        "### Pipeline + ToMe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4qCwFnmsmk7"
      },
      "outputs": [],
      "source": [
        "import tomesd\n",
        "\n",
        "model_id = \"Zero-nnkn/stable-diffusion-2-pokemon\"\n",
        "pipeline = StableDiffusionPipeline.from_pretrained(model_id)\n",
        "tomesd.apply_patch(pipeline, ratio=0.5)\n",
        "pipeline.to(CPU_DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfKtvDKWA_Tn"
      },
      "outputs": [],
      "source": [
        "t = measure_latency(pipeline, prompt, nsteps=NUM_STEPS , nimg=NUM_IMAGES)\n",
        "print(f'\\n{t} (s/image)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lOrSABXzhbV"
      },
      "outputs": [],
      "source": [
        "del pipeline\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x86Hn5wB7Baz"
      },
      "source": [
        "### ONNX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TX9zG9LpDA4G"
      },
      "outputs": [],
      "source": [
        "from optimum.onnxruntime import ORTStableDiffusionPipeline\n",
        "\n",
        "model_id = \"Zero-nnkn/stable-diffusion-2-pokemon\"\n",
        "revision=\"onnx\"\n",
        "pipeline = ORTStableDiffusionPipeline.from_pretrained(\n",
        "    model_id,\n",
        "    revision=revision\n",
        ")\n",
        "pipeline.to(CPU_DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jiZYJY4a7XVr"
      },
      "outputs": [],
      "source": [
        "t = measure_latency(pipeline, prompt, nsteps=NUM_STEPS - 1, nimg=NUM_IMAGES)\n",
        "print(f'\\n{t} (s/image)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLFaCF-z7YkF"
      },
      "outputs": [],
      "source": [
        "del pipeline\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJkcvz-07Y7Z"
      },
      "source": [
        "### ONNX UINT8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hmo8YumDGryg"
      },
      "outputs": [],
      "source": [
        "from optimum.onnxruntime import ORTStableDiffusionPipeline\n",
        "\n",
        "model_id = \"Zero-nnkn/stable-diffusion-2-pokemon\"\n",
        "revision=\"onnx-u8\"\n",
        "pipeline = ORTStableDiffusionPipeline.from_pretrained(\n",
        "    model_id,\n",
        "    revision=revision\n",
        ")\n",
        "\n",
        "pipeline.to(CPU_DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AH3xcIiu7k2_"
      },
      "outputs": [],
      "source": [
        "t = measure_latency(pipeline, prompt, nsteps=NUM_STEPS -1, nimg=NUM_IMAGES)\n",
        "print(f'\\n{t} (s/image)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKd_G5M67law"
      },
      "outputs": [],
      "source": [
        "del pipeline\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22g8kbvC7m5f"
      },
      "source": [
        "### OpenVINO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlUh7tl07n91"
      },
      "outputs": [],
      "source": [
        "from optimum.intel import OVStableDiffusionPipeline\n",
        "\n",
        "model_id = \"Zero-nnkn/stable-diffusion-2-pokemon\"\n",
        "revision=\"openvino\"\n",
        "pipeline = OVStableDiffusionPipeline.from_pretrained(\n",
        "    model_id,\n",
        "    revision=revision,\n",
        "    device='CPU',\n",
        "    compile=False,\n",
        ")\n",
        "\n",
        "\n",
        "batch_size, num_images, height, width = 1, 1, 512, 512\n",
        "# Statically reshape the model\n",
        "pipeline.reshape(batch_size, height, width, num_images)\n",
        "# Compile the model before inference\n",
        "pipeline.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "030Bh6hw8GzB"
      },
      "outputs": [],
      "source": [
        "t = measure_latency(pipeline, prompt, nsteps=NUM_STEPS - 1, nimg=NUM_IMAGES)\n",
        "print(f'\\n{t} (s/image)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUYW3V-18HWG"
      },
      "outputs": [],
      "source": [
        "del pipeline\n",
        "torch.cuda.empty_cache()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}